import { Ionicons } from "@expo/vector-icons";
import { AudioModule } from "expo-audio";
import * as Speech from "expo-speech";
import { useCallback, useEffect, useRef, useState } from "react";
import {
   Alert,
   Linking,
   Platform,
   Text,
   TouchableOpacity,
   View,
} from "react-native";
import { useTheme } from "../../lib/ThemeContext";

// Voice recognition not available in Expo managed workflow
// Would need to eject to bare React Native to use @react-native-voice/voice
let Voice = null;

export const VoiceControl = ({
   onNextOrder,
   onPrevOrder,
   onSelectOrder,
   ordersLength,
}) => {
   const { theme } = useTheme();
   const [isVoiceListening, setIsVoiceListening] = useState(false);
   const [voiceStatus, setVoiceStatus] = useState(
      "Tap to start voice commands"
   );
   const [showVoiceStatus, setShowVoiceStatus] = useState(false);
   const [voiceStatusType, setVoiceStatusType] = useState("info");
   const [hasPermission, setHasPermission] = useState(false);

   const recognitionRef = useRef(null);
   const isListeningRef = useRef(false);
   const isManualStopRef = useRef(false);

   // Update ref when state changes to avoid closure issues
   useEffect(() => {
      isListeningRef.current = isVoiceListening;
      console.log("üìä Voice Listening State:", isVoiceListening);
   }, [isVoiceListening]);

   // Check microphone permissions on component mount
   useEffect(() => {
      const checkInitialPermissions = async () => {
         try {
            const permissions =
               await AudioModule.getRecordingPermissionsAsync();
            console.log("üé§ Initial permission status:", permissions);
            setHasPermission(permissions.granted);

            // Update initial status based on permissions
            if (permissions.granted) {
               setVoiceStatus("Tap to start voice commands");
            } else {
               setVoiceStatus("Tap to grant microphone access");
            }
         } catch (error) {
            console.error("‚ùå Error checking initial permissions:", error);
            setHasPermission(false);
            setVoiceStatus("Microphone permission required");
         }
      };

      const initializeNativeVoice = async () => {
         // Native voice recognition is not available in Expo managed workflow
         console.log("üé§ Checking native voice availability...");
         console.log(
            "‚ùå Voice module not available - Expo managed workflow limitation"
         );
      };
      checkInitialPermissions();
      initializeNativeVoice();

      // Cleanup voice listeners on unmount
      return () => {
         // No native voice cleanup needed in Expo
         console.log("üßπ Cleaning up voice control component");
      };
   }, []);

   // Request microphone permission using expo-audio
   const requestMicrophonePermission = async () => {
      try {
         console.log("üé§ Requesting microphone permission with expo-audio...");

         // Check current permissions first
         const currentPermissions =
            await AudioModule.getRecordingPermissionsAsync();
         console.log("üé§ Current permission status:", currentPermissions);

         if (currentPermissions.granted) {
            console.log("‚úÖ Permission already granted");
            setHasPermission(true);
            return true;
         }

         // Request permissions
         const { status, granted } =
            await AudioModule.requestRecordingPermissionsAsync();
         console.log("üé§ Permission request result:", { status, granted });

         if (granted) {
            console.log("‚úÖ Microphone permission granted");
            setHasPermission(true);
            setVoiceStatus("‚úÖ Microphone access granted");
            setVoiceStatusType("success");
            setShowVoiceStatus(true);
            setTimeout(() => setShowVoiceStatus(false), 2000);
            return true;
         } else {
            console.log("‚ùå Microphone permission denied");
            setHasPermission(false);
            setVoiceStatus("‚ùå Microphone access required");
            setVoiceStatusType("error");
            setShowVoiceStatus(true);

            Alert.alert(
               "Microphone Permission Required",
               "This app needs microphone access to process voice commands. Please grant permission in your device settings.",
               [
                  {
                     text: "Cancel",
                     style: "cancel",
                     onPress: () => setShowVoiceStatus(false),
                  },
                  {
                     text: "Open Settings",
                     onPress: () => {
                        // Open device settings for the app
                        if (Platform.OS === "ios") {
                           // iOS: open app settings
                           Linking.openURL("app-settings:");
                        } else {
                           // Android: open app info settings
                           Linking.openSettings();
                        }
                     },
                  },
               ]
            );
            return false;
         }
      } catch (error) {
         console.error("‚ùå Error requesting microphone permission:", error);
         setHasPermission(false);
         setVoiceStatus("‚ùå Permission request failed");
         setVoiceStatusType("error");
         setShowVoiceStatus(true);
         return false;
      }
   };

   // Initialize Web Speech Recognition for web platform
   const initializeWebSpeechRecognition = useCallback(() => {
      if (Platform.OS !== "web") return null;

      if (typeof window === "undefined") return null;

      const SpeechRecognition =
         window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
         console.log("‚ùå Web Speech Recognition not supported");
         return null;
      }

      console.log("‚úÖ Initializing Web Speech Recognition");
      const recognition = new SpeechRecognition();

      recognition.continuous = true;
      recognition.interimResults = false;
      recognition.lang = "en-US";

      recognition.onstart = () => {
         console.log("üé§ Web Speech Recognition started");
         setVoiceStatus("üé§ Listening...");
         setVoiceStatusType("info");
         setShowVoiceStatus(true);
      };

      recognition.onresult = (event) => {
         console.log("üó£Ô∏è Speech result received");
         const results = event.results;
         const lastResult = results[results.length - 1];

         if (lastResult.isFinal) {
            const transcript = lastResult[0].transcript.toLowerCase().trim();
            console.log("‚úÖ Final transcript:", transcript);
            processVoiceCommand(transcript);
         }
      };

      recognition.onerror = (event) => {
         console.error("‚ùå Speech recognition error:", event.error);
         if (event.error === "not-allowed") {
            setVoiceStatus("‚ùå Microphone access denied");
            setVoiceStatusType("error");
            setShowVoiceStatus(true);
            Alert.alert(
               "Microphone Access Required",
               "Please allow microphone access to use voice commands. You may need to enable microphone permissions in your browser or device settings.",
               [
                  { text: "Cancel", style: "cancel" },
                  {
                     text: "Check Settings",
                     onPress: () => {
                        if (Platform.OS === "web") {
                           // For web, suggest checking browser permissions
                           Alert.alert(
                              "Browser Permissions",
                              "In your browser:\n1. Click the lock/info icon in the address bar\n2. Allow microphone access for this site\n3. Refresh the page and try again"
                           );
                        }
                     },
                  },
               ]
            );
         } else if (event.error === "no-speech") {
            setVoiceStatus("üîá No speech detected - try again");
            setVoiceStatusType("error");
            setShowVoiceStatus(true);
            setTimeout(() => setShowVoiceStatus(false), 3000);
         } else {
            setVoiceStatus(`‚ùå Speech error: ${event.error}`);
            setVoiceStatusType("error");
            setShowVoiceStatus(true);
            setTimeout(() => setShowVoiceStatus(false), 4000);
         }
      };

      recognition.onend = () => {
         console.log("‚èπÔ∏è Speech recognition ended");
         if (!isManualStopRef.current && isListeningRef.current) {
            console.log("üîÑ Restarting speech recognition");
            try {
               recognition.start();
            } catch (error) {
               console.error("‚ùå Error restarting recognition:", error);
            }
         }
      };

      return recognition;
   }, []);

   // Helper function to convert spoken numbers to digits
   const convertSpokenToNumber = (text) => {
      const numberMap = {
         zero: 0,
         one: 1,
         two: 2,
         to: 2,
         three: 3,
         four: 4,
         for: 4,
         five: 5,
         six: 6,
         seven: 7,
         eight: 8,
         nine: 9,
         ten: 10,
         eleven: 11,
         twelve: 12,
         thirteen: 13,
         fourteen: 14,
         fifteen: 15,
         sixteen: 16,
         seventeen: 17,
         eighteen: 18,
         nineteen: 19,
         twenty: 20,
      };

      for (const [word, num] of Object.entries(numberMap)) {
         if (text.includes(word)) {
            return num;
         }
      }
      return null;
   };

   // Speak feedback to user
   const speakFeedback = useCallback((text) => {
      if (Platform.OS !== "web") {
         Speech.speak(text, {
            language: "en-US",
            pitch: 1.0,
            rate: 0.9,
         });
      }
   }, []);

   // Process voice commands
   const processVoiceCommand = useCallback(
      (transcript) => {
         console.log("üîä RAW TRANSCRIPT RECEIVED:", transcript);
         console.log("üìè Transcript length:", transcript.length);
         console.log("üî§ Original case:", transcript);

         const command = transcript.toLowerCase().trim();
         console.log("üé§ PROCESSED COMMAND:", command);
         console.log(
            "üìù Processing voice command at:",
            new Date().toLocaleTimeString()
         );
         console.log("üìä Available orders count:", ordersLength);

         setVoiceStatus(`Heard: "${command}"`);
         setVoiceStatusType("info");
         setShowVoiceStatus(true);

         setTimeout(() => setShowVoiceStatus(false), 3000);

         if (
            command.includes("next order") ||
            command.includes("next orders")
         ) {
            console.log("‚úÖ COMMAND MATCHED: Next Order");
            onNextOrder();
            const feedback = "Moving to next order";
            setVoiceStatus(`‚úÖ ${feedback}`);
            setVoiceStatusType("success");
            setShowVoiceStatus(true);
            speakFeedback(feedback);
            setTimeout(() => setShowVoiceStatus(false), 2000);
         } else if (
            command.includes("previous order") ||
            command.includes("previous orders") ||
            command.includes("prev order") ||
            command.includes("back")
         ) {
            console.log("‚úÖ COMMAND MATCHED: Previous Order");
            onPrevOrder();
            const feedback = "Moving to previous order";
            setVoiceStatus(`‚úÖ ${feedback}`);
            setVoiceStatusType("success");
            setShowVoiceStatus(true);
            speakFeedback(feedback);
            setTimeout(() => setShowVoiceStatus(false), 2000);
         } else if (
            command.includes("open") ||
            command.includes("show") ||
            command.includes("go to")
         ) {
            console.log("‚úÖ COMMAND MATCHED: Open Order");
            let orderNumber = null;

            // First try to extract digit number
            const digitMatch = command.match(
               /(?:open|show|go to)\s+(?:order\s+)?(\d+)/
            );
            if (digitMatch) {
               orderNumber = parseInt(digitMatch[1]);
               console.log("üî¢ EXTRACTED DIGIT:", orderNumber);
            } else {
               // Try to extract spoken number
               const spokenNumber = convertSpokenToNumber(command);
               if (spokenNumber !== null) {
                  orderNumber = spokenNumber;
               }
            }

            if (orderNumber !== null) {
               const orderIndex = orderNumber - 1; // Convert to 0-based index
               if (orderIndex >= 0 && orderIndex < ordersLength) {
                  onSelectOrder(orderIndex);
                  const feedback = `Opening order ${orderNumber}`;
                  setVoiceStatus(`‚úÖ ${feedback}`);
                  setVoiceStatusType("success");
                  setShowVoiceStatus(true);
                  speakFeedback(feedback);
                  setTimeout(() => setShowVoiceStatus(false), 2000);
               } else {
                  const feedback = `Order ${orderNumber} not found`;
                  setVoiceStatus(`‚ùå ${feedback}`);
                  setVoiceStatusType("error");
                  setShowVoiceStatus(true);
                  speakFeedback(feedback);
                  setTimeout(() => setShowVoiceStatus(false), 2500);
               }
            } else {
               const feedback = "Order number unclear";
               setVoiceStatus(`‚ùå ${feedback}`);
               setVoiceStatusType("error");
               setShowVoiceStatus(true);
               speakFeedback(feedback);
               setTimeout(() => setShowVoiceStatus(false), 2000);
            }
         } else if (command.includes("stop") || command.includes("quit")) {
            stopListening();
         }
         // Don't show error for unrecognized commands, just ignore them
      },
      [onNextOrder, onPrevOrder, onSelectOrder, ordersLength, speakFeedback]
   );

   // Initialize speech recognition based on platform
   const initializeSpeechRecognition = useCallback(() => {
      console.log("üéØ INITIALIZING SPEECH RECOGNITION");
      console.log("üì± Platform:", Platform.OS);

      // For web platform - use Web Speech API
      if (Platform.OS === "web") {
         if (
            typeof window !== "undefined" &&
            ("webkitSpeechRecognition" in window ||
               "SpeechRecognition" in window)
         ) {
            console.log("‚úÖ WEB SPEECH RECOGNITION AVAILABLE");
            const SpeechRecognition =
               window.SpeechRecognition || window.webkitSpeechRecognition;
            const recognition = new SpeechRecognition();

            recognition.continuous = true;
            recognition.interimResults = true; // Enable interim results to see partial speech
            recognition.lang = "en-US";

            recognition.onstart = () => {
               console.log("üé§ WEB SPEECH RECOGNITION STARTED");
               console.log("‚è∞ Started at:", new Date().toLocaleTimeString());
               console.log("üåê Recognition language:", recognition.lang);
               console.log("üîÑ Continuous mode:", recognition.continuous);
               console.log("üìù Interim results:", recognition.interimResults);
               setVoiceStatus("üé§ Listening for speech...");
               setVoiceStatusType("info");
               setShowVoiceStatus(true);
               setTimeout(() => setShowVoiceStatus(false), 2000);
            };

            recognition.onresult = (event) => {
               console.log("üó£Ô∏è WEB SPEECH DETECTED - Raw event:", event);
               console.log("üìä Total results count:", event.results.length);

               const results = event.results;

               // Log all results (both interim and final)
               for (let i = 0; i < results.length; i++) {
                  const result = results[i];
                  const transcript = result[0].transcript;
                  const confidence = result[0].confidence;

                  if (result.isFinal) {
                     console.log(`‚úÖ FINAL RESULT [${i}]:`, transcript);
                     console.log(`üéØ Confidence: ${confidence}`);
                  } else {
                     console.log(`‚è≥ INTERIM RESULT [${i}]:`, transcript);
                  }
               }

               const lastResult = results[results.length - 1];

               if (lastResult.isFinal) {
                  const transcript = lastResult[0].transcript;
                  console.log("üé§ PROCESSING FINAL TRANSCRIPT:", transcript);
                  processVoiceCommand(transcript);
               } else {
                  const interimTranscript = lastResult[0].transcript;
                  console.log("üëÇ LISTENING (interim):", interimTranscript);
               }
            };

            recognition.onerror = (event) => {
               console.error("‚ùå WEB SPEECH RECOGNITION ERROR:", event.error);
               setVoiceStatus(`‚ùå Speech error: ${event.error}`);
               setVoiceStatusType("error");
               setShowVoiceStatus(true);
               setTimeout(() => setShowVoiceStatus(false), 3000);
            };

            recognition.onend = () => {
               console.log("‚èπÔ∏è WEB SPEECH RECOGNITION ENDED");
               console.log("‚è∞ Ended at:", new Date().toLocaleTimeString());
               console.log("üèÅ Manual stop?", isManualStopRef.current);
               console.log("üëÇ Still listening?", isListeningRef.current);

               if (!isManualStopRef.current && isListeningRef.current) {
                  console.log(
                     "üîÑ AUTO-RESTARTING WEB SPEECH RECOGNITION in 1 second..."
                  );
                  setTimeout(() => {
                     if (!isManualStopRef.current && isListeningRef.current) {
                        console.log("‚ñ∂Ô∏è RESTARTING SPEECH RECOGNITION NOW");
                        recognition.start();
                     } else {
                        console.log("‚ùå CONDITIONS CHANGED - NOT RESTARTING");
                     }
                  }, 1000);
               } else {
                  console.log(
                     "üõë NOT RESTARTING - Manual stop or not listening"
                  );
               }
            };

            recognitionRef.current = recognition;
            return recognition;
         } else {
            console.log(
               "‚ùå WEB SPEECH RECOGNITION NOT SUPPORTED IN THIS BROWSER"
            );
            return null;
         }
      }
      // For Android/iOS - speech recognition not available in Expo managed workflow
      else if (Platform.OS === "android" || Platform.OS === "ios") {
         console.log("‚ùå NATIVE SPEECH RECOGNITION NOT AVAILABLE IN EXPO");
         console.log(
            "‚ÑπÔ∏è React Native doesn't have built-in speech recognition"
         );
         console.log(
            "‚ÑπÔ∏è Would need native speech recognition library like @react-native-voice/voice"
         );
         return null;
      } else {
         console.log("‚ùå SPEECH RECOGNITION NOT AVAILABLE ON THIS PLATFORM");
         return null;
      }
   }, [processVoiceCommand]);

   // Start real speech recognition
   const startRealSpeechRecognition = useCallback(async () => {
      console.log("üöÄ ATTEMPTING TO START REAL SPEECH RECOGNITION");

      // For mobile platforms, speech recognition not available in Expo managed workflow
      if (Platform.OS === "android" || Platform.OS === "ios") {
         console.log(
            "üì± Mobile platform detected - speech recognition requires ejecting from Expo"
         );
         return false;
      }

      // For web, use Web Speech API
      const speechRecognition = initializeSpeechRecognition();

      if (speechRecognition && typeof speechRecognition.start === "function") {
         try {
            console.log("‚ñ∂Ô∏è STARTING WEB SPEECH RECOGNITION");
            speechRecognition.start();
            return true;
         } catch (error) {
            console.error("‚ùå FAILED TO START WEB SPEECH RECOGNITION:", error);
            return false;
         }
      }

      return false;
   }, [initializeSpeechRecognition]);

   // Stop real speech recognition
   const stopRealSpeechRecognition = useCallback(async () => {
      // For mobile platforms, no native voice to stop
      if (Platform.OS === "android" || Platform.OS === "ios") {
         console.log("üì± Mobile platform - no speech recognition to stop");
         return;
      }

      // Stop web speech recognition
      if (recognitionRef.current) {
         console.log("‚èπÔ∏è STOPPING WEB SPEECH RECOGNITION");
         recognitionRef.current.stop();
      }
   }, []);

   // Start voice listening - ONLY real speech recognition, no simulation
   const startListening = useCallback(async () => {
      try {
         console.log("üöÄ STARTING REAL VOICE CONTROL");
         console.log("üìä Orders available:", ordersLength);

         // Check permissions first
         if (!hasPermission) {
            console.log("üîí Requesting microphone permission...");
            const permissionGranted = await requestMicrophonePermission();
            if (!permissionGranted) {
               console.log("‚ùå Permission denied, cannot start voice control");
               return;
            }
         }

         setIsVoiceListening(true);
         isListeningRef.current = true;
         isManualStopRef.current = false;

         console.log("‚úÖ REFS SET - isListeningRef:", isListeningRef.current);

         // ONLY try real speech recognition - no simulation fallback
         const realSpeechStarted = startRealSpeechRecognition();

         if (realSpeechStarted) {
            console.log("‚úÖ REAL SPEECH RECOGNITION STARTED");
            setVoiceStatus("üé§ Listening for voice commands...");
            setVoiceStatusType("info");
            setShowVoiceStatus(true);
            speakFeedback("Voice control activated - speak your command");
            setTimeout(() => setShowVoiceStatus(false), 3000);

            Alert.alert(
               "Voice Control Active",
               "üé§ Real speech recognition is now listening!\n\nSpeak these commands:\n‚Ä¢ 'Next order'\n‚Ä¢ 'Previous order'\n‚Ä¢ 'Open order [number]'\n‚Ä¢ 'Stop'\n\nSpeak clearly into your microphone.",
               [{ text: "OK" }]
            );
         } else {
            console.log("‚ùå SPEECH RECOGNITION NOT AVAILABLE");
            setIsVoiceListening(false);
            isListeningRef.current = false;

            let errorMessage = "‚ùå Speech recognition not available";
            let alertTitle = "Voice Control Not Available";
            let alertMessage = "";

            if (Platform.OS === "android") {
               errorMessage =
                  "‚ùå Speech recognition requires ejecting from Expo";
               alertTitle = "Android Voice Control Solution";
               alertMessage =
                  "üöÄ To get REAL speech recognition working on Android:\n\n‚úÖ SOLUTION:\n1. Eject from Expo managed workflow:\n   `npx expo run:android` or `npx expo eject`\n\n2. Install native speech library:\n   `npm install @react-native-voice/voice`\n\n3. Link the native dependencies\n\nüéØ ALTERNATIVE:\n‚Ä¢ Use the web version in browser\n‚Ä¢ Web Speech API works perfectly\n\n‚ö†Ô∏è Current Expo managed workflow cannot access native speech recognition APIs.";
            } else if (Platform.OS === "ios") {
               errorMessage =
                  "‚ùå Speech recognition requires ejecting from Expo";
               alertTitle = "iOS Voice Control Solution";
               alertMessage =
                  "üöÄ To get REAL speech recognition working on iOS:\n\n‚úÖ SOLUTION:\n1. Eject from Expo managed workflow:\n   `npx expo run:ios` or `npx expo eject`\n\n2. Install native speech library:\n   `npm install @react-native-voice/voice`\n\n3. Configure iOS permissions\n\nüéØ ALTERNATIVE:\n‚Ä¢ Use the web version in browser\n‚Ä¢ Web Speech API works perfectly\n\n‚ö†Ô∏è Current Expo managed workflow cannot access native speech recognition APIs.";
            } else {
               alertMessage =
                  "‚ùå Speech recognition is not available on this platform.\n\nSupported platforms:\n‚Ä¢ Web browsers with microphone access\n‚Ä¢ Desktop browsers (Chrome, Firefox, Safari)\n\nFor mobile devices, please use the web version in your browser.";
            }

            setVoiceStatus(errorMessage);
            setVoiceStatusType("error");
            setShowVoiceStatus(true);
            setTimeout(() => setShowVoiceStatus(false), 4000);

            Alert.alert(alertTitle, alertMessage, [{ text: "OK" }]);
         }
      } catch (error) {
         console.error("‚ùå ERROR STARTING VOICE CONTROL:", error);
         setIsVoiceListening(false);
         isListeningRef.current = false;
         setVoiceStatus("‚ùå Failed to start voice control");
         setVoiceStatusType("error");
         setShowVoiceStatus(true);
         setTimeout(() => setShowVoiceStatus(false), 3000);
      }
   }, [
      hasPermission,
      requestMicrophonePermission,
      speakFeedback,
      startRealSpeechRecognition,
   ]);

   // Stop voice listening - ONLY real speech recognition
   const stopListening = useCallback(() => {
      try {
         console.log("‚èπÔ∏è STOPPING VOICE CONTROL");
         isManualStopRef.current = true;
         isListeningRef.current = false;

         // Stop real speech recognition if active
         if (recognitionRef.current) {
            console.log("üõë STOPPING REAL SPEECH RECOGNITION");
            recognitionRef.current.stop();
            recognitionRef.current = null;
         }

         setIsVoiceListening(false);
         const statusText = "üîá Voice control stopped";
         setVoiceStatus(statusText);
         setVoiceStatusType("info");
         setShowVoiceStatus(true);
         speakFeedback("Voice control deactivated");
         setTimeout(() => setShowVoiceStatus(false), 2000);
         console.log("‚úÖ VOICE CONTROL STOPPED SUCCESSFULLY");
      } catch (error) {
         console.error("‚ùå ERROR STOPPING VOICE CONTROL:", error);
         setIsVoiceListening(false);
         isListeningRef.current = false;
      }
   }, [speakFeedback]);

   // Toggle voice recognition
   const toggleVoiceRecognition = useCallback(() => {
      console.log(
         `üîÑ TOGGLING VOICE CONTROL - Currently: ${
            isVoiceListening ? "ON" : "OFF"
         }`
      );
      if (isVoiceListening) {
         stopListening();
      } else {
         startListening();
      }
   }, [isVoiceListening, startListening, stopListening]);

   // Cleanup on unmount
   useEffect(() => {
      return () => {
         isManualStopRef.current = true;

         // Stop any active speech recognition
         if (recognitionRef.current) {
            recognitionRef.current.stop();
            recognitionRef.current = null;
         }
      };
   }, []);

   // Get status colors based on type
   const getStatusColors = () => {
      switch (voiceStatusType) {
         case "success":
            return {
               backgroundColor: "#22c55e",
               borderColor: "#16a34a",
               textColor: "#ffffff",
            };
         case "error":
            return {
               backgroundColor: "#ef4444",
               borderColor: "#dc2626",
               textColor: "#ffffff",
            };
         default:
            return {
               backgroundColor: "#ff6b35",
               borderColor: "#ff8c42",
               textColor: "#ffffff",
            };
      }
   };

   const statusColors = getStatusColors();

   return (
      <>
         <View
            style={{
               position: "absolute",
               bottom: 10,
               right: 10,
               zIndex: 1000,
            }}
         >
            <TouchableOpacity
               onPress={toggleVoiceRecognition}
               style={{
                  width: 56,
                  height: 56,
                  borderRadius: 20,
                  backgroundColor: isVoiceListening
                     ? "#ff6b35"
                     : hasPermission
                     ? "#2c3e50"
                     : "#8e8e93",
                  borderWidth: 2,
                  borderColor: isVoiceListening
                     ? "#ff8c42"
                     : hasPermission
                     ? "#34495e"
                     : "#aeaeb2",
                  justifyContent: "center",
                  alignItems: "center",
                  shadowColor: isVoiceListening ? "#ff6b35" : "#2c3e50",
                  shadowOffset: {
                     width: 0,
                     height: isVoiceListening ? 8 : 4,
                  },
                  shadowOpacity: isVoiceListening ? 0.6 : 0.3,
                  shadowRadius: isVoiceListening ? 15 : 6,
                  elevation: isVoiceListening ? 12 : 6,
                  transform: [
                     { scale: isVoiceListening ? 1.1 : 1 },
                     { rotate: isVoiceListening ? "2deg" : "0deg" },
                  ],
               }}
               activeOpacity={0.7}
            >
               <Ionicons
                  name={
                     isVoiceListening
                        ? "mic"
                        : hasPermission
                        ? "mic-outline"
                        : "mic-off"
                  }
                  size={28}
                  color="#ffffff"
               />
            </TouchableOpacity>
         </View>

         {/* Voice Status Display */}
         {showVoiceStatus && voiceStatus && (
            <View
               style={{
                  position: "absolute",
                  bottom: 80,
                  right: 10,
                  zIndex: 999,
                  maxWidth: 250,
               }}
            >
               <View
                  style={{
                     backgroundColor: statusColors.backgroundColor,
                     borderRadius: 12,
                     padding: 12,
                     borderWidth: 2,
                     borderColor: statusColors.borderColor,
                     shadowColor: statusColors.backgroundColor,
                     shadowOffset: { width: 0, height: 6 },
                     shadowOpacity: 0.4,
                     shadowRadius: 8,
                     elevation: 8,
                     transform: [{ scale: 1.02 }],
                  }}
               >
                  <Text
                     style={{
                        fontSize: 13,
                        color: statusColors.textColor,
                        fontWeight: "600",
                        textAlign: "center",
                        textShadowColor: "rgba(0, 0, 0, 0.3)",
                        textShadowOffset: { width: 1, height: 1 },
                        textShadowRadius: 2,
                     }}
                  >
                     {voiceStatusType === "success"
                        ? "‚úÖ"
                        : voiceStatusType === "error"
                        ? "‚ùå"
                        : "üé§"}{" "}
                     {voiceStatus}
                  </Text>
               </View>
            </View>
         )}
      </>
   );
};
